---

title: No LLM can solve this - Lost in the Middle
date_now: 2024-02-06
url: "https://youtu.be/1ww8RlFC8uI"
aliases: ["No LLM can solve this - Lost in the Middle"]
channel: "code_your_own_AI"
published: 2024-01-14T05:00:00-08:00
thumbnail: "https://img.youtube.com/vi/1ww8RlFC8uI/maxresdefault.jpg"
keywords: ["artificial intelligence", "AI models", "LLM", "VLM", "VLA", "Multi-modal model", "explanatory video", "RAG", "multi-AI", "multi-agent", "Fine-tune", "Pre-train", "RLHF"]
duration: 15m 8s
watching_IN_progress: true
watched_completely : false
notes_taken: false
---


# No LLM can solve this - Lost in the Middle



![thumbnail | 250](https://img.youtube.com/vi/1ww8RlFC8uI/maxresdefault.jpg)



```
Is it possible, for any current LLM, to solve this simple task (a 2K prompt)? Any LLM, open-source or proprietary? Intensive testing revealed, that there is an extreme limited amount of LLMs that can solve my simple task, even with a text redundancy of 2 (!) in the prompt! No reasoning involved, just to find info in a text prompt w/ 2k token length. Happy RAG-time!

My test prompt is 1105 words long, contains 8293 characters and (w/ my tokenizer) close to 2k tokens long. I tested no LLM with a context length below 2k. 

The prompt is too long to upload to YouTube. 

DIY: Generate any topic specific text and simply insert a paragraph of text (maybe with a task description) twice somewhere in the "lost" middle. Smile. 
I tested it for astrophysics, aerodynamic, geography and cooking. 

Now you know why professional RAG systems have a text redundancy of 4 to 6 for every alpha-reranked information  .... did I mention, that I have a dedicated video on Self-RAG? 
https://www.youtube.com/watch?v=i4V9iJcxzZ4

So ... is RAG the solution? Not quite; it primarily addresses the existing shortcomings in our LLMs, sometimes.

#aieducation 
#performancetesting 
#airesearch
```




https://youtu.be/1ww8RlFC8uI



https://youtu.be/1ww8RlFC8uI


